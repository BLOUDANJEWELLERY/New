<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Stereo Pair Capture with Smart Feedback</title>
  <style>
    body {
      text-align: center;
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }
    h2 {
      margin-top: 20px;
    }
    #videoContainer {
      position: relative;
      display: inline-block;
      max-width: 100%;
    }
    #video {
      width: 100%;
      max-width: 640px;
      height: auto;
      border: 2px solid black;
    }
    /* The ghost overlay shows the left capture at reduced opacity so the live feed is visible */
    #ghostOverlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      max-width: 640px;
      height: auto;
      opacity: 0.3;
      pointer-events: none;
      display: none;
    }
    #instruction {
      margin-top: 10px;
      font-size: 1.1em;
      color: #333;
    }
    #buttons {
      margin-top: 10px;
    }
    #images {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 10px;
      margin-top: 10px;
    }
    #images img {
      width: 100%;
      max-width: 300px;
      height: auto;
      border: 1px solid #ccc;
    }
  </style>
</head>
<body>
  <h2>Capture Stereo Pair Images</h2>
  <div id="videoContainer">
    <video id="video" autoplay playsinline></video>
    <img id="ghostOverlay" src="" alt="Ghost Overlay" />
  </div>
  <div id="instruction">Capture the left image to begin.</div>
  <div id="buttons">
    <button id="captureLeft">Capture Left Image</button>
    <button id="captureRight" disabled>Auto Capture Right Image</button>
  </div>
  <canvas id="canvas" style="display: none;"></canvas>
  <div id="images">
    <img id="leftImage" alt="Left Image" />
    <img id="rightImage" alt="Right Image" />
  </div>

  <script>
    const video = document.getElementById("video");
    const captureLeftBtn = document.getElementById("captureLeft");
    const captureRightBtn = document.getElementById("captureRight");
    const instruction = document.getElementById("instruction");
    const canvas = document.getElementById("canvas");
    const leftImage = document.getElementById("leftImage");
    const rightImage = document.getElementById("rightImage");
    const ghostOverlay = document.getElementById("ghostOverlay");

    let stream;
    let leftTaken = false;
    let leftFrameData = null; // store the left image's pixel data

    // Thresholds for region analysis (tweak these as needed)
    const LEFT_REGION_THRESHOLD = 8;    // average difference in left quarter (should remain stable)
    const RIGHT_REGION_THRESHOLD = 20;  // average difference in right quarter (should increase as camera moves right)
    const RATIO_THRESHOLD = 2;          // ratio of right to left differences

    // Request the back camera on mobile (or default camera on desktop)
    navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } })
      .then(s => {
        stream = s;
        video.srcObject = stream;
      })
      .catch(error => { console.error("Error accessing webcam: ", error); });

    // Capture an image from the video feed and return its data URL.
    function captureImage(imageElement) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const dataURL = canvas.toDataURL("image/png");
      imageElement.src = dataURL;
      return dataURL;
    }

    // Compute average per-pixel difference for a given vertical region from startX to endX.
    function getRegionDifference(imgData1, imgData2, startX, endX) {
      const { width, height, data: data1 } = imgData1;
      const data2 = imgData2.data;
      let diffSum = 0;
      let count = 0;
      for (let y = 0; y < height; y++) {
        for (let x = startX; x < endX; x++) {
          const index = (y * width + x) * 4;
          const rDiff = Math.abs(data1[index] - data2[index]);
          const gDiff = Math.abs(data1[index + 1] - data2[index + 1]);
          const bDiff = Math.abs(data1[index + 2] - data2[index + 2]);
          const avgPixelDiff = (rDiff + gDiff + bDiff) / 3;
          diffSum += avgPixelDiff;
          count++;
        }
      }
      return diffSum / count;
    }

    // When the left image is captured, display it as ghost overlay,
    // update instructions, and start the motion-detection loop.
    captureLeftBtn.addEventListener("click", () => {
      // Capture left image and display it.
      captureImage(leftImage);
      ghostOverlay.src = leftImage.src;
      ghostOverlay.style.display = "block";
      leftTaken = true;
      captureLeftBtn.disabled = true;
      captureRightBtn.disabled = false;
      instruction.innerText = "Left image captured. Now slowly move your camera to the right (without zooming) until indicated.";
      
      // Store left image pixel data.
      const ctx = canvas.getContext("2d");
      leftFrameData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      
      // Begin checking for optimal movement.
      setTimeout(detectMotion, 500);
    });

    // Checks if the camera has been moved “just enough” to be ideal for stereo capture.
    function detectMotion() {
      if (!leftTaken) return;
      
      // Capture current frame.
      const tempCanvas = document.createElement("canvas");
      tempCanvas.width = video.videoWidth;
      tempCanvas.height = video.videoHeight;
      const tempCtx = tempCanvas.getContext("2d");
      tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
      const currentFrameData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
      
      const totalWidth = leftFrameData.width;
      // Define two regions:
      const leftRegionEnd = Math.floor(totalWidth / 4);  // left quarter, which should stay virtually the same
      const rightRegionStart = Math.floor((3 * totalWidth) / 4); // right quarter, where differences should appear
      
      const leftDiff = getRegionDifference(leftFrameData, currentFrameData, 0, leftRegionEnd);
      const rightDiff = getRegionDifference(leftFrameData, currentFrameData, rightRegionStart, totalWidth);
      
      // Update instruction based on current differences.
      instruction.innerText = `Adjust camera: Left Diff = ${leftDiff.toFixed(1)}, Right Diff = ${rightDiff.toFixed(1)}.`;
      
      // Check conditions: left region remains stable while right region shows significant difference.
      if (leftDiff < LEFT_REGION_THRESHOLD &&
          rightDiff > RIGHT_REGION_THRESHOLD &&
          (rightDiff/(leftDiff+0.1)) > RATIO_THRESHOLD) {
        // Optimal movement reached; capture the right image.
        captureImage(rightImage);
        ghostOverlay.style.display = "none";
        captureRightBtn.disabled = true;
        instruction.innerText = "Stereo pair captured automatically!";
        alert("Stereo pair captured with optimal displacement!");
      } else {
        // Continue checking. (Give user feedback with updated diff values.)
        setTimeout(detectMotion, 500);
      }
    }
  </script>
</body>
</html>