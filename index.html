<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Stereo Capture with Auto-Alignment</title>
  <style>
    body {
      background: #111;
      color: white;
      text-align: center;
      font-family: sans-serif;
      margin: 0;
    }
    #canvasWrapper {
      position: relative;
      display: inline-block;
    }
    #canvas {
      border: 2px solid #444;
    }
    #centerArrow {
      position: absolute;
      top: 50%;
      left: 50%;
      font-size: 32px;
      color: lime;
      transform: translate(-50%, -50%);
      pointer-events: none;
    }
    button {
      margin-top: 12px;
      padding: 10px 20px;
      font-size: 16px;
    }
    #photo1, #photo2 {
      max-width: 45%;
      margin: 10px;
    }
  </style>
</head>
<body>
  <h2>Guided Stereo Photo Capture</h2>

  <video id="video" autoplay playsinline muted style="display:none;"></video>
  <div id="canvasWrapper">
    <canvas id="canvas"></canvas>
    <div id="centerArrow">➤</div>
  </div>

  <br>
  <button id="captureBtn">Capture First Photo</button>
  <p id="status">Waiting for camera...</p>

  <img id="photo1" />
  <img id="photo2" />

  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvas');
    let ctx = canvas.getContext('2d');
    let captureBtn = document.getElementById('captureBtn');
    let status = document.getElementById('status');
    let photo1 = document.getElementById('photo1');
    let photo2 = document.getElementById('photo2');
    
    let point = null, tracking = false, prevGray = null, autoCaptured = false;
    let photo1Taken = false;

    navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } })
      .then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          requestAnimationFrame(draw);
          status.textContent = "Ready. Capture first photo.";
        };
      })
      .catch(err => {
        status.textContent = "Camera access error: " + err;
      });

    captureBtn.onclick = () => {
      if (!photo1Taken) {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        photo1.src = canvas.toDataURL("image/jpeg");
        photo1Taken = true;
        status.textContent = "Click the object in photo to track.";
        captureBtn.disabled = true;
      }
    };

    canvas.addEventListener("click", (e) => {
      if (photo1Taken && !tracking) {
        let rect = canvas.getBoundingClientRect();
        point = {
          x: e.clientX - rect.left,
          y: e.clientY - rect.top
        };
        prevGray = new cv.Mat();
        let src = new cv.Mat(canvas.height, canvas.width, cv.CV_8UC4);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        src.data.set(imageData.data);
        cv.cvtColor(src, prevGray, cv.COLOR_RGBA2GRAY);
        src.delete();
        tracking = true;
        status.textContent = "Tracking object. Align red dot to green ➤.";
      }
    });

    function draw() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (tracking && point) {
        let currentGray = new cv.Mat();
        let src = new cv.Mat(canvas.height, canvas.width, cv.CV_8UC4);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        src.data.set(imageData.data);
        cv.cvtColor(src, currentGray, cv.COLOR_RGBA2GRAY);

        let prevPts = cv.matFromArray(1, 1, cv.CV_32FC2, [point.x, point.y]);
        let nextPts = new cv.Mat(), statusArr = new cv.Mat(), err = new cv.Mat();

        cv.calcOpticalFlowPyrLK(prevGray, currentGray, prevPts, nextPts, statusArr, err);

        if (statusArr.data[0]) {
          point.x = nextPts.data32F[0];
          point.y = nextPts.data32F[1];

          ctx.beginPath();
          ctx.arc(point.x, point.y, 10, 0, 2 * Math.PI);
          ctx.fillStyle = "red";
          ctx.fill();

          let cx = canvas.width / 2;
          let cy = canvas.height / 2;
          let dist = Math.hypot(point.x - cx, point.y - cy);

          if (dist < 20 && !autoCaptured) {
            autoCaptured = true;
            setTimeout(() => {
              ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
              photo2.src = canvas.toDataURL("image/jpeg");
              status.textContent = "Second photo auto-captured!";
            }, 300);
          }

        } else {
          status.textContent = "Tracking lost.";
          tracking = false;
        }

        prevGray.delete();
        prevGray = currentGray.clone();

        src.delete(); currentGray.delete(); prevPts.delete(); nextPts.delete(); statusArr.delete(); err.delete();
      }

      requestAnimationFrame(draw);
    }
  </script>
</body>
</html>